{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adversial_nnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mi9CgNTcV2AZ","executionInfo":{"status":"ok","timestamp":1625068870567,"user_tz":-360,"elapsed":3325,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"52bec066-202a-4bca-94d5-cf44dba098dc"},"source":["!pip install keras"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"590qjagNQQfV","executionInfo":{"status":"ok","timestamp":1625068879100,"user_tz":-360,"elapsed":3417,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"b2e0963f-119a-4ee8-fc93-fe3eabb29735"},"source":["!pip install --upgrade adversarial-robustness-toolbox"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: adversarial-robustness-toolbox in /usr/local/lib/python3.7/dist-packages (1.7.0)\n","Requirement already satisfied, skipping upgrade: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.41.1)\n","Requirement already satisfied, skipping upgrade: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numba~=0.53.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.53.1)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.0.0)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox) (1.0.1)\n","Requirement already satisfied, skipping upgrade: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba~=0.53.1->adversarial-robustness-toolbox) (0.36.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0LG7IGBhVXxk"},"source":["from keras.layers.normalization import BatchNormalization\n","from keras.layers import Conv2D, Dense, Activation, GlobalAveragePooling2D, MaxPooling2D\n","from keras import regularizers, initializers\n","\n","# total params: 0.27M in vgg-20\n","\n","momentum = 0.9\n","epsilon = 1e-5\n","weight_decay = 1e-4\n","\n","\n","def conv_bn_relu(x, filters, name, kernel_size=(3, 3), strides=(1, 1)):\n","    \"\"\"conv2D + batch normalization + relu activation\"\"\"\n","\n","    x = Conv2D(\n","        filters, kernel_size,\n","        strides=strides, padding='same', use_bias=False,\n","        kernel_initializer=initializers.he_normal(),\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        name=name + '_conv2D'\n","    )(x)\n","    x = BatchNormalization(momentum=momentum, epsilon=epsilon, name=name + '_BN')(x)\n","    x = Activation('relu', name=name + '_relu')(x)\n","    return x\n","\n","\n","def conv_blocks(x, filters, num_blocks, name):\n","    \"\"\"two conv, downsampling if dimension not match\"\"\"\n","\n","    for i in range(num_blocks):\n","        if int(x.shape[-1]) != filters:\n","            x = conv_bn_relu(x, filters, strides=(2, 2), name=name + '_blk{}_conv1'.format(i + 1))\n","        else:\n","            x = conv_bn_relu(x, filters, name + '_blk{}_conv1'.format(i + 1))\n","        x = conv_bn_relu(x, filters, name + '_blk{}_conv2'.format(i + 1))\n","    return x\n","\n","\n","def vgg_model(x, num_classes, num_blocks):\n","    \"\"\"sequential model without shortcut, same number of parameters as its resnet counterpart\"\"\"\n","\n","    # level 0:\n","    # input: 32x32x3; output: 32x32x16\n","    x = conv_bn_relu(x, 16, name='lv0')\n","\n","    # level 1:\n","    # input: 32x32x16; output: 32x32x16\n","    x = conv_blocks(x, 16, num_blocks, name='lv1')\n","\n","    # level 2:\n","    # input: 32x32x16; output: 16x16x32\n","    x = conv_blocks(x, 32, num_blocks, name='lv2')\n","\n","    # level 3:\n","    # input: 16x16x32; output: 8x8x64\n","    x = conv_blocks(x, 64, num_blocks, name='lv3')\n","\n","    # output\n","    x = GlobalAveragePooling2D(name='global_pool')(x)\n","    x = Dense(\n","        num_classes,\n","        activation='softmax',\n","        kernel_initializer=initializers.he_normal(),\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        name='FC'\n","    )(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"s77z5iZqVNhO","executionInfo":{"status":"error","timestamp":1625062312836,"user_tz":-360,"elapsed":22,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"304bcab5-f1ad-4f39-a1ba-b717c6e49f0d"},"source":["from keras.datasets import cifar10\n","\n","\n","from keras.layers import Input\n","import numpy as np\n","import random\n","import tensorflow as tf\n","\n","from art.classifiers import KerasClassifier\n","from art.attacks import TargetedUniversalPerturbation\n","from art.utils import random_sphere\n","\n","from keras import utils, Model\n","from tensorflow.keras.utils import to_categorical\n","\n","# load data\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","norm2_mean = 0\n","for im in x_train:\n","    norm2_mean += np.linalg.norm(im.flatten(), ord=2)\n","norm2_mean /= len(x_train)\n","\n","# normalize data\n","channel_mean = np.mean(x_train, axis=(0, 1, 2))\n","channel_std = np.std(x_train, axis=(0, 1, 2))\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","for i in range(3):\n","    x_train[:, :, :, i] = (x_train[:, :, :, i] - channel_mean[i]) / channel_std[i]\n","    x_test[:, :, :, i] = (x_test[:, :, :, i] - channel_mean[i]) / channel_std[i]\n","\n","# labels to categorical\n","num_classes = 10\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)\n","\n","# randomly selecting 1000 images for each class in 10 classes \n","trainIdx = []\n","num_each_class = 10\n","for class_i in range(10):\n","    np.random.seed(111)\n","    idx = np.random.choice( np.where(y_train[:, class_i]==1)[0], num_each_class, replace=False ).tolist()\n","    trainIdx = trainIdx + idx\n","random.shuffle(trainIdx)\n","x_train, y_train = x_train[trainIdx], y_train[trainIdx]\n","\n","# build vgg model\n","num_blocks = 3\n","img_input = Input(shape=(32, 32, 3), name='input')\n","img_prediction = vgg_model(img_input, num_classes, num_blocks)\n","model = Model(img_input, img_prediction)\n","model.load_weights(\"vgg_20_1553198546.h5\")\n","\n","# build targeted UAP\n","\n","\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","classifier = KerasClassifier(model=model)\n","adv_crafter = TargetedUniversalPerturbation(\n","    classifier,\n","    attacker='fgsm',\n","    delta=0.000001,\n","    attacker_params={'targeted':True, 'eps':0.006},\n","    max_iter=10,\n","    eps=5.5,\n","    norm=2)\n","\n","# set target label\n","target = 1\n","y_train_adv_tar = np.zeros(y_train.shape)\n","for i in range(y_train.shape[0]):\n","    y_train_adv_tar[i, target] = 1.0\n","\n","# generate noise\n","_ = adv_crafter.generate(x_train, y=y_train_adv_tar)\n","noise = adv_crafter.noise[0,:]\n","norm2_ori = np.linalg.norm(noise.flatten(), ord=2)\n","\n","# targeted UAP result\n","print('=== Targeted UAP ===')\n","rescaled_noise = noise.copy()\n","for i in range(3):\n","    rescaled_noise[:, :, i] = rescaled_noise[:, :, i] * channel_std[i]\n","norm2 = np.linalg.norm(rescaled_noise.flatten(), ord=2)\n","normInf = np.abs(rescaled_noise.flatten()).max()\n","print('norm2: {:.1f} %'.format(norm2/norm2_mean*100))\n","\n","x_train_adv = x_train + noise\n","x_test_adv = x_test + noise\n","\n","preds_train_adv = np.argmax(classifier.predict(x_train_adv), axis=1)\n","preds_test_adv = np.argmax(classifier.predict(x_test_adv), axis=1) \n","targeted_success_rate_train = np.sum(preds_train_adv == target) / len(x_train)\n","targeted_success_rate_test = np.sum(preds_test_adv == target) / len(x_test) \n","print('targeted_success_rate_train: {:.1f} %'.format(targeted_success_rate_train*100))\n","print('targeted_success_rate_test: {:.1f} %'.format(targeted_success_rate_test*100))\n","\n","np.save('noise.npy', noise)\n","\n","# random noise result \n","print('=== Random Noise ===')\n","rescaled_noise_rand = random_sphere(nb_points=1,nb_dims=(32*32*3),radius=norm2_ori,norm=2)\n","rescaled_noise_rand = rescaled_noise_rand.reshape(32,32,3)\n","noise_rand = rescaled_noise_rand.copy()\n","for i in range(3):\n","    noise_rand[:, :, i] = noise_rand[:, :, i] * channel_std[i]\n","norm2_rand = np.linalg.norm(noise_rand.flatten(), ord=2)\n","normInf_rand = np.abs(noise_rand.flatten()).max()\n","print('norm2_rand: {:.1f} %'.format(norm2_rand/norm2_mean*100))\n","\n","x_train_adv_rand = x_train + noise_rand\n","x_test_adv_rand = x_test + noise_rand\n","\n","preds_train_adv_rand = np.argmax(classifier.predict(x_train_adv_rand), axis=1)\n","preds_test_adv_rand = np.argmax(classifier.predict(x_test_adv_rand), axis=1)\n","targeted_success_rate_train_rand = np.sum(preds_train_adv_rand == target) / len(x_train)\n","targeted_success_rate_test_rand = np.sum(preds_test_adv_rand == target) / len(x_test)\n","print('targeted_success_rate_train_rand: {:.1f} %'.format(targeted_success_rate_train_rand*100))\n","print('targeted_success_rate_test_rand: {:.1f} %'.format(targeted_success_rate_test_rand*100))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-bea323b53790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTargetedUniversalPerturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_sphere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'TargetedUniversalPerturbation' from 'art.attacks' (/usr/local/lib/python3.7/dist-packages/art/attacks/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSY1WjcYpnfi","executionInfo":{"status":"ok","timestamp":1625068931130,"user_tz":-360,"elapsed":14494,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"332a9fc3-020b-4f01-c135-61d7d12b831b"},"source":["# Loading the dataset\n","\n","from keras.datasets import cifar10\n","(train_images, train_labels), (test_images, test_labels)= cifar10.load_data()\n","\n","# Labels before applying the function\n","# Training set labels\n","print(train_labels)\n","print(train_labels.shape)\n","\n","# Testing set labels\n","print(test_labels)\n","print(test_labels.shape)\n","\n","# Applying the function to training set labels and testing set labels\n","from tensorflow.keras.utils import to_categorical\n","train_labels = to_categorical(train_labels, dtype =\"uint8\")\n","test_labels = to_categorical(test_labels, dtype =\"uint8\")\n","\n","# Labels after applying the function\n","# Training set labels\n","print(train_labels)\n","print(train_labels.shape)\n","\n","# Testing set labels\n","print(test_labels)\n","print(test_labels.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n","170508288/170498071 [==============================] - 11s 0us/step\n","[[6]\n"," [9]\n"," [9]\n"," ...\n"," [9]\n"," [1]\n"," [1]]\n","(50000, 1)\n","[[3]\n"," [8]\n"," [8]\n"," ...\n"," [5]\n"," [1]\n"," [7]]\n","(10000, 1)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 1 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 0]]\n","(50000, 10)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]]\n","(10000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JezcnaNiSamG"},"source":["!pip  install tensorflow "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"fzYVlFaCs35V","executionInfo":{"status":"error","timestamp":1625069413520,"user_tz":-360,"elapsed":2147,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"af513656-87cc-4bb0-bfeb-8edba9ba89cf"},"source":["import tensorflow.compat.v1 as tf\n","import numpy as np\n","\n","\n","from keras.models import Sequential\n","\n","\n","from art.attacks.evasion import FastGradientMethod\n","from art.estimators.classification import TensorFlowClassifier\n","from art.utils import load_mnist\n","\n","# Step 1: Load the MNIST dataset\n","\n","(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n","\n","# Step 2: Create the model\n","\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","input_ph = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n","labels_ph = tf.placeholder(tf.int32, shape=[None, 10])\n","\n","x = tf.layers.conv2d(input_ph, filters=4, kernel_size=5, activation=tf.nn.relu)\n","x = tf.layers.max_pooling2d(x, 2, 2)\n","x = tf.layers.conv2d(x, filters=10, kernel_size=5, activation=tf.nn.relu)\n","x = tf.layers.max_pooling2d(x, 2, 2)\n","x = tf.layers.flatten(x)\n","x = tf.layers.dense(x, 100, activation=tf.nn.relu)\n","logits = tf.layers.dense(x, 10)\n","\n","loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=labels_ph))\n","optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n","train = optimizer.minimize(loss)\n","\n","# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","# tf.compat.v1.keras.backend.set_session(sess)\n","\n","sess.run(tf.global_variables_initializer())\n","\n","# Step 3: Create the ART classifier\n","\n","classifier = TensorFlowClassifier(\n","    clip_values=(min_pixel_value, max_pixel_value),\n","    input_ph=input_ph,\n","    output=logits,\n","    labels_ph=labels_ph,\n","    train=train,\n","    loss=loss,\n","    learning=None,\n","    sess=sess,\n","    preprocessing_defences=[],\n",")\n","\n","# Step 4: Train the ART classifier\n","\n","classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)\n","\n","# Step 5: Evaluate the ART classifier on benign test examples\n","\n","predictions = classifier.predict(x_test)\n","accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n","\n","# Step 6: Generate adversarial test examples\n","attack = FastGradientMethod(estimator=classifier, eps=0.2)\n","x_test_adv = attack.generate(x=x_test)\n","\n","# Step 7: Evaluate the ART classifier on adversarial test examples\n","\n","predictions = classifier.predict(x_test_adv)\n","accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n","print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n","  warnings.warn('`tf.layers.conv2d` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/pooling.py:310: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n","  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n","  warnings.warn('`tf.layers.flatten` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-6aec21ff1e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mlearning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mpreprocessing_defences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/tensorflow.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_ph, output, labels_ph, train, loss, learning, sess, channels_first, clip_values, preprocessing_defences, postprocessing_defences, preprocessing, feed_dict)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Get the internal layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Get the loss gradients graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/tensorflow.py\u001b[0m in \u001b[0;36m_get_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# Get the computational graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# Get the list of operators and heuristically filter them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEBbj51IbnFe","executionInfo":{"status":"ok","timestamp":1625065160450,"user_tz":-360,"elapsed":535,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"7eee2652-0f1d-45c2-b62d-3d4a6a893a43"},"source":["import tensorflow\n","print(tensorflow.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.5.0\n"],"name":"stdout"}]}]}