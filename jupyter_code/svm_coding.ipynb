{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svm_coding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMaOIEfAe8z0AXmfibZhnrC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"kLD0FKTxTxW5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617630432940,"user_tz":-360,"elapsed":30967,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"f4577a09-b669-425b-ee0d-854ae7cda831"},"source":["import numpy as np\n","import pandas as pd\n","import statsmodels.api as sm\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split as tts\n","from sklearn.metrics import accuracy_score, recall_score, precision_score\n","from sklearn.utils import shuffle\n","# >> FEATURE SELECTION << #\n","\n","\n","# >> MODEL TRAINING << #\n","def compute_cost(W, X, Y):\n","    # calculate hinge loss\n","    N = X.shape[0]\n","    distances = 1 - Y * (np.dot(X, W))\n","    print(\"distances\")\n","    \n","    \n","    distances[distances < 0] = 0  # equivalent to max(0, distance)\n","    print(distances[0:10])\n","    print(len(distances))\n","    hinge_loss = regularization_strength * (np.sum(distances) / N)\n","    #print(hinge_loss)\n","\n","    # calculate cost\n","    cost = 1 / 2 * np.dot(W, W) + hinge_loss\n","    return cost\n","\n","\n","# I haven't tested it but this same function should work for\n","# vanilla and mini-batch gradient descent as well\n","def calculate_cost_gradient(W, X_batch, Y_batch):\n","\n","    distance = 1 - (Y_batch * np.dot(X_batch, W))\n","\n","\n","    # dw = np.zeros(len(W))\n","\n","    if distance < 0:\n","        di = W\n","    else:\n","        di = W - (regularization_strength * Y_batch * X_batch)\n","       \n","  \n","    return di\n","\n","\n","def sgd(features, outputs):\n","    max_epochs = 5000\n","    print(\"sgd\")\n","    weights = np.zeros(features.shape[1])\n","    #print(weights)\n","    nth = 0\n","    prev_cost = float(\"inf\")\n","    print(prev_cost)\n","    cost_threshold = 0.01  # in percent\n","    # stochastic gradient descent\n","    for epoch in range(1, max_epochs):\n","        # shuffle to prevent repeating update cycles\n","        X, Y = shuffle(features, outputs)\n","        for ind, x in enumerate(X):\n","           \n","            ascent = calculate_cost_gradient(weights, x, Y[ind])\n","            \n","          \n","            weights = weights - (learning_rate * ascent)\n","        # print(ascent)\n","        # print(\"ascent\")\n","        # print(weights)\n","            \n","\n","        # convergence check on 2^nth epoch\n","        if epoch == 2 ** nth or epoch == max_epochs - 1:\n","            cost = compute_cost(weights, features, outputs)\n","            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n","            # stoppage criterion\n","            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n","                return weights\n","            prev_cost = cost\n","            nth += 1\n","    return weights\n","\n","\n","########################\n","\n","\n","def init():\n","\n","    print(\"reading dataset...\")\n","    # read data in pandas (pd) data frame\n","    data = pd.read_table('mixed200.txt')\n","    data = data.drop(\"No.\", axis=1)\n","    data = data.drop(\"StdPageRank\", axis=1)\n","    data = data.drop(\"VarPageRank\", axis=1)\n","\n","\n","    state_map = {1: 1.0, 0: -1.0}\n","    data['State'] = data['State'].map(state_map)\n","\n","    print(data['State'])\n","\n","    # put features & outputs in different data frames\n","\n","    training = 57748\n","    testing = 24749\n","    Y = data.loc[:, 'State']\n","    X = data.iloc[:, 0:9]\n","  \n","    \n","    # filter features\n","    # remove_correlated_features(X)\n","    # remove_less_significant_features(X, Y)\n","\n","    # normalize data for better convergence and to prevent overflow\n","    X_normalized = MinMaxScaler().fit_transform(X.values)\n","    X = pd.DataFrame(X_normalized)\n","\n","    # insert 1 in every row for intercept b\n","    X.insert(loc=len(X.columns), column='intercept', value=1)\n","\n","    # split data into train and test set\n","    print(\"splitting dataset into train and test sets...\")\n","    X_train, X_test, y_train, y_test = X[0:training],X[training:testing+training],Y[0:training],Y[training:testing+training]\n","    \n","\n","    # train the model\n","    print(\"training started...\")\n","    print(X_train.to_numpy())\n","    print(y_train.to_numpy())\n","    W = sgd(X_train.to_numpy(), y_train.to_numpy())\n","    print(\"training finished.\")\n","    print(\"weights are: {}\".format(W))\n","\n","    # testing the model\n","    print(\"testing the model...\")\n","\n","\n","    y_test_predicted = np.array([])\n","    for i in range(X_test.shape[0]):\n","        yp = np.sign(np.dot(X_test.to_numpy()[i], W))\n","        y_test_predicted = np.append(y_test_predicted, yp)\n","\n","    print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n","    print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n","    print(\"precision on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n","\n","\n","# set hyper-parameters and call init\n","regularization_strength = 10000\n","learning_rate = 0.000001\n","init()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["reading dataset...\n","0       -1.0\n","1        1.0\n","2        1.0\n","3        1.0\n","4        1.0\n","        ... \n","82492    1.0\n","82493   -1.0\n","82494    1.0\n","82495    1.0\n","82496    1.0\n","Name: State, Length: 82497, dtype: float64\n","splitting dataset into train and test sets...\n","training started...\n","[[0.11023622 0.22282609 0.48       ... 0.50275256 0.40259816 1.        ]\n"," [0.11811024 0.13586957 0.08       ... 0.08785124 0.3761839  1.        ]\n"," [0.11023622 0.15217391 0.04       ... 0.06245647 0.39304146 1.        ]\n"," ...\n"," [0.61417323 0.65217391 0.24       ... 0.0530874  0.0571629  1.        ]\n"," [0.88976378 0.92391304 0.32       ... 0.04744484 0.00378517 1.        ]\n"," [0.11811024 0.17934783 0.08       ... 0.1024238  0.38613903 1.        ]]\n","[-1.  1.  1. ... -1. -1.  1.]\n","sgd\n","inf\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 1 and Cost is: 485.77229234745926\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 2 and Cost is: 431.5368411840653\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 4 and Cost is: 397.5327170809333\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 8 and Cost is: 382.01235512457623\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 16 and Cost is: 377.26271388714224\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 32 and Cost is: 381.58912522873214\n","distances\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","57748\n","Epoch is: 64 and Cost is: 382.50598608291654\n","training finished.\n","weights are: [-7.44042249  3.28137626 -1.72033158  0.80332604 -3.96982391  0.5400112\n","  1.87250616 -3.04683359 -1.70238834  1.97260102]\n","testing the model...\n","accuracy on test dataset: 0.9854135520627096\n","recall on test dataset: 1.0\n","precision on test dataset: 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KisNn3cfC3gG","executionInfo":{"status":"ok","timestamp":1617527360383,"user_tz":-360,"elapsed":10320,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"3a200f90-ad91-4b6f-edc8-ef1038c19f19"},"source":["from sklearn.svm import SVC\n","#from sklearn.svm import LinearSVC\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import accuracy_score\n","import pandas\n","\n","dataframe = pandas.read_table('/content/mixed200.txt')\n","data = dataframe.drop(\"No.\", axis=1)\n","data = data.drop(\"StdPageRank\", axis=1)\n","data = data.drop(\"VarPageRank\", axis=1)\n","dataset = data.values\n","\n","# split into input (X) and output (Y) variables\n","training = 57748\n","testing = 24749\n","\n","l = 82497\n","X = dataset[:,0:]\n","# print(X.shape)\n","labels = []\n","for i in range (0,l):\n","  if X[i][9] == 1:\n","    labels.append(1)\n","  else:\n","    labels.append(0)\n","\n","features = X[0:l,0:9]\n","\n","\n","\n","\n","# Split our data\n","train, test, train_labels, test_labels = features[0:training],features[training:testing+training],labels[0:training],labels[training:testing+training]\n","gnb = SVC()\n","# Train our classifier\n","print(len(train_labels))\n","model =gnb.fit(train,train_labels)\n","preds = gnb.predict(test)\n","print(\"----------------------------SVM--------------------------\")\n","print(accuracy_score(test_labels, preds))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["57748\n","----------------------------SVM--------------------------\n","0.9873126186916643\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26ckhFeIWZgc","executionInfo":{"status":"ok","timestamp":1620409738956,"user_tz":-360,"elapsed":2300,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"31b88785-719e-4ea9-c753-8579b75d5175"},"source":["\n","import pandas\n","import numpy as np\n","\n","dataframe = pandas.read_table('/content/dos200.txt')\n","\n","print(list(dataframe.min(axis=0)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 10.0, 14.0, 2.0, 1.0, 2.0, 0.0, 0.018149025707461245, 0.046498117468674376, 0.008328770082628284, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HmFw0L4erhIo","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"error","timestamp":1620393971539,"user_tz":-360,"elapsed":1206,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"ecd53647-d543-46c6-86e1-141d18276be5"},"source":["#fuzzy\n","\n","long double Min[10]={-100.0, 10.0, 13.0, 2.0, 0.0, 2.0, 0.0, 0.005301991866120557, 0.02717618228088004, 0.0011771647097430305};\n","long double Max[10]={-194.0, 132.0, 199.0, 16.0, 1.0, 17.0, 1.0, 0.12536496993782908, 0.1888784481405464, 0.044515632825592434};\n","\n","\n","#rpm\n","\n","long double Max[10]={-100.0, 27.0, 86.0, 22.0, 2.0, 20.0, 2.0, 0.12536496993782908, 0.3408619464499469, 0.044515632825592434};\n","long double Min[10]={-100, 10.0, 13.0, 2.0, 0.0, 2.0, 0.0, 0.02248266777655021, 0.048092654043031015, 0.005555555555555557};\n","\n","#replay\n","long double Min[10]={-100.0, 10.0, 13.0, 2.0, 0.0, 2.0, 0.0, 0.015437591081532804, 0.04615917891672077, 0.0034883720930232558};\n","long double Max[10]={-100, 43.0, 126.0, 13.0, 1.0, 11.0, 1.0, 0.12536496993782908, 0.15252770010406091, 0.044515632825592434};"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9b3409df3cb9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    long double Min[10]={-100.0, 10.0, 13.0, 2.0, 0.0, 2.0, 0.0, 0.005301991866120557, 0.02717618228088004, 0.0011771647097430305, 0.005665557571710649, 3.209854259836787e-05};\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"HR_fEHxpYKKJ","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"error","timestamp":1620409492334,"user_tz":-360,"elapsed":4201,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"e4268fc2-106f-4d11-f75f-b7f936973d81"},"source":["long double Max[10]={-100.0, 27.0, 100.0, 27.0, 2.0, 27.0, 2.0, 0.12630540975054774, 0.4744080648877346, 0.04184995700600018};\n","long double Min[10]={-100.0, 10.0, 14.0, 2.0, 1.0, 2.0, 0.0, 0.018149025707461245, 0.046498117468674376, 0.008328770082628284};"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-d2ad6812b5c9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    long double Max[10]={-100.0, 27.0, 100.0, 27.0, 2.0, 27.0, 2.0, 0.12630540975054774, 0.4744080648877346, 0.04184995700600018};\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}]}