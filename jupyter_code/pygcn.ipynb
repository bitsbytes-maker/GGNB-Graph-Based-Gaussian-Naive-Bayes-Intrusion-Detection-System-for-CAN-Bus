{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pygcn.ipynb","provenance":[],"authorship_tag":"ABX9TyNIlWYwz0+oqUWJUE3Mw+fv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"P5-Ic8bY9lCB","executionInfo":{"status":"ok","timestamp":1612357088011,"user_tz":-360,"elapsed":1728,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}}},"source":["import math\r\n","\r\n","import torch\r\n","\r\n","from torch.nn.parameter import Parameter\r\n","from torch.nn.modules.module import Module\r\n","\r\n","\r\n","class GraphConvolution(Module):\r\n","    \"\"\"\r\n","    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\r\n","    \"\"\"\r\n","\r\n","    def __init__(self, in_features, out_features, bias=True):\r\n","        super(GraphConvolution, self).__init__()\r\n","        self.in_features = in_features\r\n","        self.out_features = out_features\r\n","        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\r\n","        if bias:\r\n","            self.bias = Parameter(torch.FloatTensor(out_features))\r\n","        else:\r\n","            self.register_parameter('bias', None)\r\n","        self.reset_parameters()\r\n","\r\n","    def reset_parameters(self):\r\n","        stdv = 1. / math.sqrt(self.weight.size(1))\r\n","        self.weight.data.uniform_(-stdv, stdv)\r\n","        if self.bias is not None:\r\n","            self.bias.data.uniform_(-stdv, stdv)\r\n","\r\n","    def forward(self, input, adj):\r\n","        support = torch.mm(input, self.weight)\r\n","        output = torch.spmm(adj, support)\r\n","        if self.bias is not None:\r\n","            return output + self.bias\r\n","        else:\r\n","            return output\r\n","\r\n","    def __repr__(self):\r\n","        return self.__class__.__name__ + ' (' \\\r\n","               + str(self.in_features) + ' -> ' \\\r\n","               + str(self.out_features) + ')'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JT37KNbH981D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFcYHpah9qLB","executionInfo":{"status":"ok","timestamp":1612357090018,"user_tz":-360,"elapsed":1492,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}}},"source":["import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","\r\n","\r\n","\r\n","class GCN(nn.Module):\r\n","    def __init__(self, nfeat, nhid, nclass, dropout):\r\n","        super(GCN, self).__init__()\r\n","\r\n","        self.gc1 = GraphConvolution(nfeat, nhid)\r\n","        self.gc2 = GraphConvolution(nhid, nclass)\r\n","        self.dropout = dropout\r\n","\r\n","    def forward(self, x, adj):\r\n","        x = F.relu(self.gc1(x, adj))\r\n","        x = F.dropout(x, self.dropout, training=self.training)\r\n","        x = self.gc2(x, adj)\r\n","        return F.log_softmax(x, dim=1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jo7VSN7u-W-v","executionInfo":{"status":"ok","timestamp":1612357139746,"user_tz":-360,"elapsed":1212,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}}},"source":["import numpy as np\r\n","import scipy.sparse as sp\r\n","import torch\r\n","\r\n","\r\n","def encode_onehot(labels):\r\n","    classes = set(labels)\r\n","    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\r\n","                    enumerate(classes)}\r\n","    labels_onehot = np.array(list(map(classes_dict.get, labels)),\r\n","                             dtype=np.int32)\r\n","    return labels_onehot\r\n","\r\n","\r\n","def load_data(path=\"../data/cora/\", dataset=\"cora\"):\r\n","    \"\"\"Load citation network dataset (cora only for now)\"\"\"\r\n","    print('Loading {} dataset...'.format(dataset))\r\n","\r\n","    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\r\n","                                        dtype=np.dtype(str))\r\n","    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\r\n","    labels = encode_onehot(idx_features_labels[:, -1])\r\n","\r\n","    # build graph\r\n","    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\r\n","    idx_map = {j: i for i, j in enumerate(idx)}\r\n","    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\r\n","                                    dtype=np.int32)\r\n","    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\r\n","                     dtype=np.int32).reshape(edges_unordered.shape)\r\n","    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\r\n","                        shape=(labels.shape[0], labels.shape[0]),\r\n","                        dtype=np.float32)\r\n","\r\n","    # build symmetric adjacency matrix\r\n","    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\r\n","\r\n","    features = normalize(features)\r\n","    adj = normalize(adj + sp.eye(adj.shape[0]))\r\n","\r\n","    idx_train = range(140)\r\n","    idx_val = range(200, 500)\r\n","    idx_test = range(500, 1500)\r\n","\r\n","    features = torch.FloatTensor(np.array(features.todense()))\r\n","    labels = torch.LongTensor(np.where(labels)[1])\r\n","    adj = sparse_mx_to_torch_sparse_tensor(adj)\r\n","\r\n","    idx_train = torch.LongTensor(idx_train)\r\n","    idx_val = torch.LongTensor(idx_val)\r\n","    idx_test = torch.LongTensor(idx_test)\r\n","\r\n","    return adj, features, labels, idx_train, idx_val, idx_test\r\n","\r\n","\r\n","def normalize(mx):\r\n","    \"\"\"Row-normalize sparse matrix\"\"\"\r\n","    rowsum = np.array(mx.sum(1))\r\n","    r_inv = np.power(rowsum, -1).flatten()\r\n","    r_inv[np.isinf(r_inv)] = 0.\r\n","    r_mat_inv = sp.diags(r_inv)\r\n","    mx = r_mat_inv.dot(mx)\r\n","    return mx\r\n","\r\n","\r\n","def accuracy(output, labels):\r\n","    preds = output.max(1)[1].type_as(labels)\r\n","    correct = preds.eq(labels).double()\r\n","    correct = correct.sum()\r\n","    return correct / len(labels)\r\n","\r\n","\r\n","def sparse_mx_to_torch_sparse_tensor(sparse_mx):\r\n","    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\r\n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\r\n","    indices = torch.from_numpy(\r\n","        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\r\n","    values = torch.from_numpy(sparse_mx.data)\r\n","    shape = torch.Size(sparse_mx.shape)\r\n","    return torch.sparse.FloatTensor(indices, values, shape)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"BRZcgurd-dRT","executionInfo":{"status":"error","timestamp":1612357311744,"user_tz":-360,"elapsed":1654,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"494af944-ed55-4276-adfd-1053d0d08f1f"},"source":["from __future__ import division\r\n","from __future__ import print_function\r\n","\r\n","import time\r\n","import argparse\r\n","import numpy as np\r\n","\r\n","import torch\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim\r\n","\r\n","adj, features, labels, idx_train, idx_val, idx_test = load_data()\r\n","\r\n","# Model and optimizer\r\n","model = GCN(nfeat=features.shape[1],\r\n","            nhid=args.hidden,\r\n","            nclass=labels.max().item() + 1,\r\n","            dropout=args.dropout)\r\n","optimizer = optim.Adam(model.parameters(),\r\n","                       lr=args.lr, weight_decay=args.weight_decay)\r\n","\r\n","if args.cuda:\r\n","    model.cuda()\r\n","    features = features.cuda()\r\n","    adj = adj.cuda()\r\n","    labels = labels.cuda()\r\n","    idx_train = idx_train.cuda()\r\n","    idx_val = idx_val.cuda()\r\n","    idx_test = idx_test.cuda()\r\n","\r\n","\r\n","def train(epoch):\r\n","    t = time.time()\r\n","    model.train()\r\n","    optimizer.zero_grad()\r\n","    output = model(features, adj)\r\n","    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\r\n","    acc_train = accuracy(output[idx_train], labels[idx_train])\r\n","    loss_train.backward()\r\n","    optimizer.step()\r\n","\r\n","    if not args.fastmode:\r\n","        # Evaluate validation set performance separately,\r\n","        # deactivates dropout during validation run.\r\n","        model.eval()\r\n","        output = model(features, adj)\r\n","\r\n","    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\r\n","    acc_val = accuracy(output[idx_val], labels[idx_val])\r\n","    print('Epoch: {:04d}'.format(epoch+1),\r\n","          'loss_train: {:.4f}'.format(loss_train.item()),\r\n","          'acc_train: {:.4f}'.format(acc_train.item()),\r\n","          'loss_val: {:.4f}'.format(loss_val.item()),\r\n","          'acc_val: {:.4f}'.format(acc_val.item()),\r\n","          'time: {:.4f}s'.format(time.time() - t))\r\n","\r\n","\r\n","def test():\r\n","    model.eval()\r\n","    output = model(features, adj)\r\n","    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\r\n","    acc_test = accuracy(output[idx_test], labels[idx_test])\r\n","    print(\"Test set results:\",\r\n","          \"loss= {:.4f}\".format(loss_test.item()),\r\n","          \"accuracy= {:.4f}\".format(acc_test.item()))\r\n","\r\n","\r\n","# Train model\r\n","t_total = time.time()\r\n","for epoch in range(args.epochs):\r\n","    train(epoch)\r\n","print(\"Optimization Finished!\")\r\n","print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\r\n","\r\n","# Testing\r\n","test()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Loading cora dataset...\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-5d9db439cfff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Model and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-1fd9b1071560>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, dataset)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n\u001b[0;32m---> 20\u001b[0;31m                                         dtype=np.dtype(str))\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_features_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_features_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: ../data/cora/cora.content not found."]}]},{"cell_type":"code","metadata":{"id":"xNkoz5iuNl69","executionInfo":{"status":"ok","timestamp":1612361217483,"user_tz":-360,"elapsed":2383,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}}},"source":["import networkx as nx\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","from scipy.linalg import fractional_matrix_power"],"execution_count":10,"outputs":[]}]}