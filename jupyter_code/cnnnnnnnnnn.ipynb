{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnnnnnnnnnn.ipynb","provenance":[],"authorship_tag":"ABX9TyOdIGIbeGJlCOnTHNU9MZ4p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oUxzKsqqWwh","executionInfo":{"status":"ok","timestamp":1617892142589,"user_tz":-360,"elapsed":5090,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"b912a4c3-6095-4268-cca1-2f7c12adf903"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","image_size = 28 # width and length\n","no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n","image_pixels = image_size * image_size\n","\n","#train_data = np.loadtxt(\"mnist_train.csv\", delimiter=\",\")\n","test_data = np.loadtxt(\"mnist_test.csv\", \n","                       delimiter=\",\")\n","\n","\n","np.array(test_data[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  7.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,  84., 185., 159., 151.,  60.,  36.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","       222., 254., 254., 254., 254., 241., 198., 198., 198., 198., 198.,\n","       198., 198., 198., 170.,  52.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,  67., 114.,  72., 114., 163.,\n","       227., 254., 225., 254., 254., 254., 250., 229., 254., 254., 140.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,  17.,  66.,  14.,  67.,  67.,\n","        67.,  59.,  21., 236., 254., 106.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  83., 253., 209.,\n","        18.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,  22., 233., 255.,  83.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129., 254., 238.,\n","        44.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,  59., 249., 254.,  62.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 133., 254., 187.,\n","         5.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   9., 205., 248.,  58.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 126., 254., 182.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,  75., 251., 240.,  57.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,  19., 221., 254., 166.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   3., 203., 254., 219.,  35.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,  38., 254., 254.,  77.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,  31., 224., 254., 115.,   1.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0., 133., 254., 254.,  52.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,  61., 242., 254., 254.,  52.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0., 121., 254., 254., 219.,\n","        40.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0., 121., 254., 207.,  18.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n","         0.,   0.,   0.,   0.])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJkIp1Lc5AVH","executionInfo":{"status":"ok","timestamp":1617892287432,"user_tz":-360,"elapsed":2183,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"76fb05d5-a030-4216-a182-ddccfadca3f9"},"source":["x = np.array(test_data[0][1:]).reshape(28,28)\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.  84. 185. 159. 151.  60.  36.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0. 222. 254. 254. 254. 254. 241. 198. 198.\n","  198. 198. 198. 198. 198. 198. 170.  52.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.  67. 114.  72. 114. 163. 227. 254. 225.\n","  254. 254. 254. 250. 229. 254. 254. 140.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  17.  66.  14.\n","   67.  67.  67.  59.  21. 236. 254. 106.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.  83. 253. 209.  18.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.  22. 233. 255.  83.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0. 129. 254. 238.  44.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.  59. 249. 254.  62.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0. 133. 254. 187.   5.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   9. 205. 248.  58.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0. 126. 254. 182.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   75. 251. 240.  57.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  19.\n","  221. 254. 166.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3. 203.\n","  254. 219.  35.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  38. 254.\n","  254.  77.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  31. 224. 254.\n","  115.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 133. 254. 254.\n","   52.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  61. 242. 254. 254.\n","   52.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 121. 254. 254. 219.\n","   40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 121. 254. 207.  18.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4-l36I5GWNw","executionInfo":{"status":"ok","timestamp":1617953756861,"user_tz":-360,"elapsed":1022,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"2019c0b6-9aed-4640-8f41-07478235a0f5"},"source":["import numpy as np\n","\n","w=np.ones((3,3,3,3))\n","\n","x = np.ones((10,3,10,10))\n","\n","out = np.zeros((10,5,5))\n","\n","for n in range(10):\n","  for m in range(2):\n","    for e in range(5):\n","      for f in range(5):\n","        for c in range(3):\n","          for r in range(3):\n","            for s in range(3):\n","              out[n][e][f]+=w[m][c][r][s]*x[n][c][e+r][f+s]\n","  \n","  print(out[n])\n","  print(\"another one\")\n","\n","\n","\n","for i in range(len(out)):\n","  print(np.array(out[i]).flatten())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[[54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]\n"," [54. 54. 54. 54. 54.]]\n","another one\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n","[54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54. 54.\n"," 54. 54. 54. 54. 54. 54. 54.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ili0ssi-oGp_"},"source":["# test harness for evaluating models on the cifar10 dataset\n","import sys\n","from matplotlib import pyplot\n","from keras.datasets import cifar10\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","\n","# load train and test dataset\n","def load_dataset():\n","\t# load dataset\n","\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n","\t# one hot encode target values\n","\ttrainY = to_categorical(trainY)\n","\ttestY = to_categorical(testY)\n","\treturn trainX, trainY, testX, testY\n","\n","# scale pixels\n","def prep_pixels(train, test):\n","\t# convert from integers to floats\n","\ttrain_norm = train.astype('float32')\n","\ttest_norm = test.astype('float32')\n","\t# normalize to range 0-1\n","\ttrain_norm = train_norm / 255.0\n","\ttest_norm = test_norm / 255.0\n","\t# return normalized images\n","\treturn train_norm, test_norm\n","\n","# define cnn model\n","def define_model():\n","\tmodel = Sequential()\n","\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n","\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","\tmodel.add(MaxPooling2D((2, 2)))\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n","\tmodel.add(Dense(10, activation='softmax'))\n","\t# compile model\n","\topt = SGD(lr=0.001, momentum=0.9)\n","\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\treturn model\n","\n","# plot diagnostic learning curves\n","def summarize_diagnostics(history):\n","\t# plot loss\n","\tpyplot.subplot(211)\n","\tpyplot.title('Cross Entropy Loss')\n","\tpyplot.plot(history.history['loss'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n","\t# plot accuracy\n","\tpyplot.subplot(212)\n","\tpyplot.title('Classification Accuracy')\n","\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n","\t# save plot to file\n","\tfilename = sys.argv[0].split('/')[-1]\n","\tpyplot.savefig(filename + '_plot.png')\n","\tpyplot.close()\n","\n","# run the test harness for evaluating a model\n","def run_test_harness():\n","\t# load dataset\n","\ttrainX, trainY, testX, testY = load_dataset()\n","\t# prepare pixel data\n","\ttrainX, testX = prep_pixels(trainX, testX)\n","\t# define model\n","\tmodel = define_model()\n","\t# fit model\n","\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n","\t# evaluate model\n","\t_, acc = model.evaluate(testX, testY, verbose=0)\n","\tprint('> %.3f' % (acc * 100.0))\n","\t# learning curves\n","\tsummarize_diagnostics(history)\n","\n","# entry point, run the test harness\n","run_test_harness()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"xeJ4kxw8nOms","executionInfo":{"status":"ok","timestamp":1617970263269,"user_tz":-360,"elapsed":991,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"7daffece-d103-44d3-8862-667abb815725"},"source":["a =[0, 0, 1, 1, 0, 0,\n","   0, 1, 0, 0, 1, 0,\n","   1, 1, 1, 1, 1, 1,\n","   1, 0, 0, 0, 0, 1,\n","   1, 0, 0, 0, 0, 1]\n","# B\n","b =[0, 1, 1, 1, 1, 0,\n","   0, 1, 0, 0, 1, 0,\n","   0, 1, 1, 1, 1, 0,\n","   0, 1, 0, 0, 1, 0,\n","   0, 1, 1, 1, 1, 0]\n","# C\n","c =[0, 1, 1, 1, 1, 0,\n","   0, 1, 0, 0, 0, 0,\n","   0, 1, 0, 0, 0, 0,\n","   0, 1, 0, 0, 0, 0,\n","   0, 1, 1, 1, 1, 0]\n","  \n","# Creating labels\n","y =[[1, 0],\n","   [0, 1],\n","   [1, 0]]\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# visualizing the data, ploting A.\n","plt.imshow(np.array(a).reshape(5, 6))\n","plt.show()\n","\n","\n","x =[np.array(a).reshape(1, 30), np.array(b).reshape(1, 30), \n","                                np.array(c).reshape(1, 30)]\n","  \n","  \n","# Labels are also converted into NumPy array\n","y = np.array(y)\n","  \n","  \n","print(x, \"\\n\\n\", y)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["[array([[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        0, 1, 1, 0, 0, 0, 0, 1]]), array([[0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n","        1, 0, 0, 1, 1, 1, 1, 0]]), array([[0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 1, 1, 1, 1, 0]])] \n","\n"," [[1 0]\n"," [0 1]\n"," [1 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pqrn48_LR_hs","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"error","timestamp":1617984887783,"user_tz":-360,"elapsed":1852,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"bdbac05c-d32f-4286-f429-ecc48d66513e"},"source":["\n","\n","def sigmoid(x):\n","    return(1/(1 + np.exp(-x)))\n","    \n","# Creating the Feed forward neural network\n","# 1 Input layer(1, 30)\n","# 1 hidden layer (1, 5)\n","# 1 output layer(3, 3)\n","  \n","def f_forward(x, w1, w2):\n","    # hidden\n","    z1 = x.dot(w1)# input from layer 1 \n","    a1 = sigmoid(z1)# out put of layer 2 \n","      \n","    # Output layer\n","    z2 = a1.dot(w2)# input of out layer\n","    a2 = sigmoid(z2)# output of out layer\n","    #print(a2)\n","    return(a2)\n","   \n","# initializing the weights randomly\n","def generate_wt(x, y):\n","    l =[]\n","    for i in range(x * y):\n","        l.append(np.random.randn())\n","    return(np.array(l).reshape(x, y))\n","      \n","# for loss we will be using mean square error(MSE)\n","def loss(out, Y):\n","    s =(np.square(out-Y))\n","    s = np.sum(s)/len(Y)\n","    return(s)\n","    \n","# Back propagation of error \n","def back_prop(x, y, w1, w2, alpha):\n","      \n","    # hiden layer\n","    z1 = x.dot(w1)# input from layer 1 \n","    a1 = sigmoid(z1)# output of layer 2 \n","      \n","    # Output layer\n","    z2 = a1.dot(w2)# input of out layer\n","    a2 = sigmoid(z2)# output of out layer\n","    # error in output layer\n","    d2 =(a2-y)\n","    d1 = np.multiply((w2.dot((d2.transpose()))).transpose(), \n","                                   (np.multiply(a1, 1-a1)))\n","  \n","    # Gradient for w1 and w2\n","    print(d1)\n","    print(d2)\n","    print(\"hokko\")\n","    w1_adj = x.transpose().dot(d1)\n","    w2_adj = a1.transpose().dot(d2)\n","      \n","    # Updating parameters\n","    w1 = w1-(alpha*(w1_adj))\n","    w2 = w2-(alpha*(w2_adj))\n","      \n","    return(w1, w2)\n","  \n","def train1(x, Y, w1, w2, alpha = 0.01, epoch = 10):\n","    acc =[]\n","    losss =[]\n","    for j in range(epoch):\n","        l =[]\n","        for i in range(len(x)):\n","            out = f_forward(x[i], w1, w2)\n","            l.append((loss(out, Y[i])))\n","            print(x[i])\n","            w1, w2 = back_prop(x[i], Y[i], w1, w2, alpha)\n","        print(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(l)/len(x)))*100)   \n","        acc.append((1-(sum(l)/len(x)))*100)\n","        losss.append(sum(l)/len(x))\n","    return(acc, losss, w1, w2)\n","   \n","def predict(x, w1, w2):\n","    Out = f_forward(x, w1, w2)\n","    maxm = 0\n","    k = 0\n","    for i in range(len(Out[0])):\n","        if(maxm<Out[0][i]):\n","            maxm = Out[0][i]\n","            k = i\n","    if(k == 0):\n","      return 0\n","        #print(\"Image is of letter A.\")\n","    elif(k == 1):\n","      return 1\n","        #print(\"Image is of letter B.\")\n","    # plt.imshow(x.reshape(5, 6))\n","    # plt.show()    \n","    \n","\n","\n","dataframe = pandas.read_table('/content/mixed200.txt')\n","data = dataframe.drop(\"No.\", axis=1)\n","data = data.drop(\"StdPageRank\", axis=1)\n","data = data.drop(\"VarPageRank\", axis=1)\n","dataset = data.values\n","\n","\n","\n","# split into input (X) and output (Y) variables\n","training = 57748\n","testing = 24749\n","\n","l = 82497\n","X = dataset[:,0:]\n","# print(X.shape)\n","labels = []\n","for i in range (0,l):\n","  if X[i][9] == 1:\n","    labels.append([0,1])\n","  else:\n","    labels.append([1,0])\n","\n","features = X[0:l,0:9]\n","\n","\n","\n","\n","# Split our data\n","train, test, train_labels, test_labels = features[0:training],features[training:testing+training],labels[0:training],labels[training:testing+training]\n","\n","\n","\n","\n","\n","train = np.array(train)\n","train_labels = np.array(train_labels)\n","\n","w1 = generate_wt(9, 5)\n","w2 = generate_wt(5, 2)\n","\n","\n","acc, losss, w1, w2 = train1(train, train_labels, w1, w2, 0.1, 100)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[2.40000000e+01 5.40000000e+01 1.40000000e+01 1.00000000e+00\n"," 1.40000000e+01 1.00000000e+00 3.25033026e-02 2.52026554e-01\n"," 1.85760014e-02]\n","[ 1.09933812e-18 -2.96750382e-13  1.05943494e-01  2.57955524e-14\n"," -5.31221717e-28]\n","[-0.71227384  0.54850989]\n","hokko\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-0432e619fdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-0432e619fdbe>\u001b[0m in \u001b[0;36mtrain1\u001b[0;34m(x, Y, w1, w2, alpha, epoch)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"======== acc:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-0432e619fdbe>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(x, y, w1, w2, alpha)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hokko\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mw1_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mw2_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (9,) and (5,) not aligned: 9 (dim 0) != 5 (dim 0)"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":782},"id":"Hpkdfgy1kwMB","executionInfo":{"status":"error","timestamp":1617986943087,"user_tz":-360,"elapsed":1592,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"29f12a32-a2ca-4b79-f9be-1c360f29d536"},"source":["import numpy as np\n","\n","\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","import pandas\n","from sklearn.metrics import accuracy_score\n","from sklearn import naive_bayes as nb\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","\n","dataframe = pandas.read_table('/content/mixed200.txt')\n","data = dataframe.drop(\"No.\", axis=1)\n","data = data.drop(\"StdPageRank\", axis=1)\n","data = data.drop(\"VarPageRank\", axis=1)\n","dataset = data.values\n","\n","\n","\n","# split into input (X) and output (Y) variables\n","training = 57748\n","testing = 24749\n","\n","l = 82497\n","X = dataset[:,0:]\n","# print(X.shape)\n","labels = []\n","for i in range (0,l):\n","  if X[i][9] == 1:\n","    labels.append([0,1])\n","  else:\n","    labels.append([1,0])\n","\n","features = X[0:l,0:9]\n","\n","\n","\n","\n","# Split our data\n","train1, test, train_labels, test_labels = features[0:training],features[training:testing+training],labels[0:training],labels[training:testing+training]\n","\n","\n","\n","\n","\n","x = np.array(train1)\n","y = np.array(train_labels)\n","\n","print(x, \"\\n\\n\", y)\n","\n","\n","\n","# activation function\n","\n","def sigmoid(x):\n","\treturn(1/(1 + np.exp(-x)))\n","\t\n","# Creating the Feed forward neural network\n","# 1 Input layer(1, 30)\n","# 1 hidden layer (1, 5)\n","# 1 output layer(3, 3)\n","\n","def f_forward(x, w1, w2):\n","\t# hidden\n","\tz1 = x.dot(w1)# input from layer 1\n","\ta1 = sigmoid(z1)# out put of layer 2\n","\t\n","\t# Output layer\n","\tz2 = a1.dot(w2)# input of out layer\n","\ta2 = sigmoid(z2)# output of out layer\n","\treturn(a2)\n","\n","# initializing the weights randomly\n","def generate_wt(x, y):\n","\tl =[]\n","\tfor i in range(x * y):\n","\t\tl.append(np.random.randn())\n","\treturn(np.array(l).reshape(x, y))\n","\t\n","# for loss we will be using mean square error(MSE)\n","def loss(out, Y):\n","\ts =(np.square(out-Y))\n","\ts = np.sum(s)/len(y)\n","\treturn(s)\n","\t\n","# Back propagation of error\n","def back_prop(x, y, w1, w2, alpha):\n","\t\n","\t# hiden layer\n","\tz1 = x.dot(w1)# input from layer 1\n","\ta1 = sigmoid(z1)# output of layer 2\n","\t\n","\t# Output layer\n","\tz2 = a1.dot(w2)# input of out layer\n","\ta2 = sigmoid(z2)# output of out layer\n","\t# error in output layer\n","\n","\td2 =(a2-y)\n","\td1 = np.multiply((w2.dot((d2.transpose()))).transpose(),(np.multiply(a1, 1-a1)))\n","\n","\t# Gradient for w1 and w2\n","\n","  \n","  \n","\tw1_adj = x.transpose().dot(d1)\n","\tw2_adj = a1.transpose().dot(d2)\n","\t\n","\t# Updating parameters\n","\tw1 = w1-(alpha*(w1_adj))\n","\tw2 = w2-(alpha*(w2_adj))\n","\t\n","\treturn(w1, w2)\n","\n","def train(x, Y, w1, w2, alpha = 0.01, epoch = 10):\n","\tacc =[]\n","\tlosss =[]\n","\tfor j in range(epoch):\n","\t\tl =[]\n","\t\tfor i in range(len(x)):\n","\t\t\tout = f_forward(x[i], w1, w2)\n","\t\t\tl.append((loss(out, Y[i])))\n","\t\t\tw1, w2 = back_prop(x[i], y[i], w1, w2, alpha)\n","\t\t#print(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(l)/len(x)))*100)\n","\t\tacc.append((1-(sum(l)/len(x)))*100)\n","\t\tlosss.append(sum(l)/len(x))\n","\treturn(acc, losss, w1, w2)\n","\n","def predict(x, w1, w2):\n","\tOut = f_forward(x, w1, w2)\n","\tmaxm = 0\n","\tk = 0\n","\tfor i in range(len(Out[0])):\n","\t\tif(maxm<Out[0][i]):\n","\t\t\tmaxm = Out[0][i]\n","\t\t\tk = i\n","\tif(k == 0):\n","\t\tprint(\"Image is of letter A.\")\n","\telif(k == 1):\n","\t\tprint(\"Image is of letter B.\")\n","\telse:\n","\t\tprint(\"Image is of letter C.\")\n","\tplt.imshow(x.reshape(5, 6))\n","\tplt.show()\t\n","\t\n","\n","w1 = generate_wt(9, 5)\n","w2 = generate_wt(5, 2)\n","\n","\n","\n","print(x[0].transpose())\n","\n","acc, losss, w1, w2 = train(x, y, w1, w2, 0.1, 100)\n","\n","\n","\n","predict(x[1], w1, w2)\n"],"execution_count":58,"outputs":[{"output_type":"stream","text":["[[2.40000000e+01 5.40000000e+01 1.40000000e+01 ... 3.25033026e-02\n","  2.52026554e-01 1.85760014e-02]\n"," [2.50000000e+01 3.80000000e+01 4.00000000e+00 ... 4.16937053e-02\n","  6.70730840e-02 1.74290747e-02]\n"," [2.40000000e+01 4.10000000e+01 3.00000000e+00 ... 4.60141055e-02\n","  5.57526778e-02 1.81610425e-02]\n"," ...\n"," [8.80000000e+01 1.33000000e+02 8.00000000e+00 ... 8.15419320e-03\n","  5.15761627e-02 3.57694591e-03]\n"," [1.23000000e+02 1.83000000e+02 1.00000000e+01 ... 6.17516336e-03\n","  4.90608397e-02 1.25924547e-03]\n"," [2.50000000e+01 4.60000000e+01 4.00000000e+00 ... 3.78277063e-02\n","  7.35691962e-02 1.78613339e-02]] \n","\n"," [[1 0]\n"," [0 1]\n"," [0 1]\n"," ...\n"," [1 0]\n"," [1 0]\n"," [0 1]]\n","[2.40000000e+01 5.40000000e+01 1.40000000e+01 1.00000000e+00\n"," 1.40000000e+01 1.00000000e+00 3.25033026e-02 2.52026554e-01\n"," 1.85760014e-02]\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-7dd088dc8c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-58-7dd088dc8c45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x, Y, w1, w2, alpha, epoch)\u001b[0m\n\u001b[1;32m    123\u001b[0m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                         \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0;31m#print(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(l)/len(x)))*100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-58-7dd088dc8c45>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(x, y, w1, w2, alpha)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mw1_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mw2_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (9,) and (5,) not aligned: 9 (dim 0) != 5 (dim 0)"]}]},{"cell_type":"code","metadata":{"id":"9wA71y8PVQoq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617966734403,"user_tz":-360,"elapsed":994,"user":{"displayName":"Maloy Kumar Devnath","photoUrl":"","userId":"08683219606020583205"}},"outputId":"de3522a6-60ba-443d-8210-323b027f4e9e"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4, 1],\n","       [2, 2]])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"S7HTbh3xSj9M"},"source":["import matplotlib.pyplot as plt1\n","  \n","# ploting accuraccy\n","plt1.plot(acc)\n","plt1.ylabel('Accuracy')\n","plt1.xlabel(\"Epochs:\")\n","plt1.show()\n","  \n","# plotting Loss\n","plt1.plot(losss)\n","plt1.ylabel('Loss')\n","plt1.xlabel(\"Epochs:\")\n","plt1.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kBFFz83SrH6"},"source":["print(w1, \"\\n\", w2)"],"execution_count":null,"outputs":[]}]}